---
title: 泛读机器学习（一），待更新
date: 2020-01-29 12:37:54
categories:
- 机器学习
tags:
- 机器学习
- 西瓜书
---
![西瓜书.png](https://i.loli.net/2020/01/29/awZObDzstEMovcg.png)


# 碎碎念
&emsp;&emsp;随着一系列机器学习相关工具包的出现，越来越多的同学往往局限于包的调用与参数替换等小格局小框架里，笔者认为这不是一个健康的学习心态。机器学习脱胎于统计学习，它的推广很大程度上基于现代计算力的提升，我们在学习和使用这些工具时亦不能忽视其内在的机理。<br>
&emsp;&emsp;本系列博文基于笔者学习[机器学习——周志华](https://item.jd.com/11867803.html)的个人心得及体会，代码实现基于`pytorch`等相关工具包，如有不足还请斧正。
* 阅读推荐
  * [《动手学深度学习》(PyTorch版)](http://tangshusen.me/Dive-into-DL-PyTorch/#/)
  * [机器学习——周志华](https://item.jd.com/11867803.html)

# 绪论
## 概念
&emsp;&emsp;所谓机器学习，即从数据中产生**模型**（model）的**学习算法**（learning algorithm）。向学习算法提供经验数据，它就能基于这些数据产生模型（i.e.训练）；在面对新的情况时，模型就会得出它基于提供数据总结出来的判断（i.e.验证）。如果说我们人类可以通过设计一套算法（不基于数据）来解决某个问题，那么机器学习就是计算机基于给定的数据通过**学习算法**生成解决问题的**模型**的过程。<br>
> 笔者注：一个很明显的区别是，人类设计的算法是显式的，是可以被他人完美复现的，原理清晰；而计算机利用学习算法得出模型的过程是隐式的，人们并不能完全弄明白其中的机理，并且这种**学习**和数据集密切相关。

&emsp;&emsp;（小注：NFL定理告诉我们，脱离具体问题空谈学习算法的好处是毫无意义的）

## 基本术语
&emsp;&emsp;要进行机器学习，首先要有数据。数据的格式一般为（特征，属性值）*e.g. （年龄，15），（身高，180）*，由这些数据组成**数据集**（data set）。从数据中学得模型的过程称为学习或**训练**（training），训练样本组成的集合称为**训练集**（training set）。这个过程通过执行某个学习算法来完成，学得的模型反映了数据的某种潜在规律，因此亦称**假设**（hypothesis）*笔者注：相对于真实规律的假设*，机器学习的过程就是根据数据不断优化假设，拟合（逼近）真实规律

&emsp;&emsp;*笔者注*：真实规律即我们希望预测的属性值，比如我们希望预测某个人是小学生还是大学生，我们的数据样例为：

| 年龄 | 身高 | 体重 | 类别 |
| :-: | :-: | :-: | :-: |
| 9 | 135 | 40 | 小学生 |
| 19 | 175 | 70 | 大学生 |

* （<年龄，9>, <身高，135>, <体重， 40>， 小学生）
* （<年龄，19>, <身高，175>, <体重， 70>， 大学生）

&emsp;&emsp;前三个键值对即（特征，属性值），数据集里的人有三个特征/标签，年龄、身高、体重，而小学生/大学生就是我们希望预测的真实规律。在机器学习里，我们就是通过这样给定的数据集去预测/拟合/逼近新的真实规律，譬如用我们训练好的模型去预测（<年龄，13>, <身高，165>, <体重， 60>）这样一个人是大学生还是小学生。

![喵内.jpg](https://i.loli.net/2020/03/02/g5xXy2wmauRiUYo.jpg)

|术语|常用助记符
|:-:|:-:
|样本|$(x, y)$
|特征/属性值|$x$
|真实值|$y$
|真实映射|$y(x)$
|预测值|$h$
|预测映射|$h(x)$

&emsp;&emsp;我们需要通过给定的多个样本找到 $x$ 与 $y$ 间的潜在规律 $y(x)$ ，即找到一个假设函数 $h(x)$ 来预测 $x$ 对应的真实值。而机器学习就是不断优化假设函数 $h(x)$ 去拟合/逼近 真实的 $y(x)$<br>
&emsp;&emsp;*笔者注*：**注意这里的函数不一定是线性映射 ！**

## 分类和回归
### 回归（Regression）
&emsp;&emsp;回归即针对连续值做预测，例如预测明天的平均气温、预测本月消费额、预测房价等，预测函数 $h(x)$ 是连续的。最常见的回归是线性回归（linear regression），即预测函数 $h(x)$ 是简单的一次函数
* [线性回归](https://baike.baidu.com/item/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/8190345?fr=aladdin)
* [多项式回归](https://baike.baidu.com/item/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92/21505384?fr=aladdin)

&emsp;&emsp;实际问题里的映射关系往往十分复杂，因此传统的回归往往难以很好的拟合假设函数

### 分类（Classification）
&emsp;&emsp;分类即针对离散值做预测，例如预测图片的种类（多分类），预测是否得糖尿病（二分类）,预测函数 $h(x)$ 依旧是连续函数，但这里有一个新的概念，阈值（threshold）。例如在预测是否得糖尿病（二分类）的问题里，我们选择某个特定的分类函数 $g(x)$ 并设定一个阈值（例如0.5），输入数据进行训练，当分类函数作用于假设函数的输出大于 0.5 则视为得了糖尿病，即：
* 得了糖尿病 —— $g(h(x)) > 0.5$
* 没得糖尿病 —— $g(h(x)) ≤ 0.5$

&emsp;&emsp;如上，训练即可拟合我们需要的假设函数。在坐标系里拟合出来的 $h(x)$ 往往是非线性的类似于边界一样的曲线，因此在分类问题里假设函数又被称作**决策边界**（decision boundary）

![decision-boundary.png](https://i.loli.net/2020/01/28/ujR5DIGbZma7Xs3.png)

&emsp;&emsp;常见的用于分类的函数有 logistic函数、tanh(x)双曲正切函数、ReLU线性修正单元等
* [logistic函数的数学推导](https://blog.csdn.net/AriesSurfer/article/details/41310525)

&emsp;&emsp;上述两类问题均可抽象为下图所示模型：

![model.png](https://i.loli.net/2020/01/28/UzV3iwfdr9vCKmp.jpg)

&emsp;&emsp;如图，输入数据（+1 为[偏置单元](https://blog.csdn.net/xwd18280820053/article/details/70681750)）训练并得到假设函数，这就是机器学习的一般流程，至于训练的细节则被隐式化了

# 模型评估与假设
## 模型评估
&emsp;&emsp;针对模型的性能度量（performance measure），我们有必要引入误差的概念：
* 误差：预测值与真实值之间的差异
* 训练误差：训练集上的误差
* 泛化误差：新样本上的误差

&emsp;&emsp;我们希望得到泛化误差小的学习器，但由于新样本的不可预测性，我们实际能做的是将经验误差近似为泛化误差，并努力使经验误差最小化。<br>
&emsp;&emsp;注意在最小化经验误差时容易出现的两个问题，过拟合（overfitting）与欠拟合（underfitting）：
![过拟合.png](https://i.loli.net/2020/01/29/Jojts9Xdi4UxKOy.png)

&emsp;&emsp;利用分层采样（stratified sampling，**保证数据集的同分布**）将数据集划分为训练集与验证集，在训练集上进行学习算法的训练与调参并在验证集上进行模型的性能度量。

&emsp;&emsp;我们常用的性能度量依据为查准率（precision）和查全率（recall），TP和FP表预测为正例：

$$P=\frac{TP}{TP+FP}\qquad R=\frac{TP}{TP+FN}$$ 

![TP_FP.jpg](https://i.loli.net/2020/01/31/NfJ1M4KHC7U8p5u.png)

&emsp;&emsp;查准率和查全率在复杂的实际应用中是一对矛盾的度量，通常情况下我们更倾向与使用F1度量（P和R的调和平局）与F$\beta$度量（P和R的调和加权平均）来进行性能度量：

$$F_1=\frac{2PR}{P+R} \quad\Rightarrow\quad F_\beta=\frac{(1+\beta^2)PR}{(1+\beta^2)P+R}$$

> &emsp;&emsp;以搜索系统为例，查准率即检索内容中符合用户期望的占比，而查全率即网络上所有符合用户期望的有效资源中检索内容的占比。一般推荐系统更倾向于高查准率（减少干扰），而检索系统更倾向于高查全率（减少遗漏）；使用F$\beta$度量，通过F$\beta$调整权重。



真正例率，假正例率，ROC曲线

$$TPR=\frac{TP}{TP+FN}\qquad FPR=\frac{FP}{TN+FP}$$

> 笔者注：显然我们希望$TPR>FPR$，即更高的$AUC$

代价敏感，加权损失函数，归一化，加权平均

## 假设检验
泛化性能，测试集的选择；统计假设检验