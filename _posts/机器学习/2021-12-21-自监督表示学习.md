---
title: 自监督表示学习（未完成）
date: 2021-12-21 00:20:06
categories:
- 机器学习
tags:
- 机器学习
- 表示学习
- 自监督学习
---

<center>Original blog：<a href="https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html">Self-Supervised Representation Learning</a></center>

* Why: Self-supervised learning empowers us to exploit a variety of labels that come with the data for free
* Aim: Learn intermediate representation that can carry good semantic or structural meanings from series of auxiliary tasks (always accompany with data augmentation) and can be beneficial to a variety of practical downstream tasks
* Key: Find proper auxiliary tasks

TODO: give a simple interpretation; BERT pretext


## Image-Based
Some auxiliary tasks used in previous works：
1. Distortion (Transformation): The pretext task is to discriminate between a set of distorted images. (e.g. translation, rotation, scaling, etc.)

![self-sup-rotation.png](https://i.loli.net/2021/09/18/qH6ZhUmpI1gfLzN.png)

&emsp;&emsp;Small distortion expectantly does not modify original semantic meaning or geometric forms of images. Slightly distorted images are considered the same as original and thus the learned features are expected to be invariant to distortion. 

2. Patches: The pretext task is to predict the relationship between multiple patches extracted from one image.

![self-sup-by-relative-position.png](https://i.loli.net/2021/09/18/ynbvsFdqGwAfCWe.png)

&emsp;&emsp;To avoid the model only catching low-level trivial signals, such as connecting a straight line across boundary or matching local patterns, we need additional noise to avert these shortcuts.
* Add gaps between patches
* Randomly downsample some patches and then upsampling it
* Randomly drop $2$ of $3$ color channels (chromatic aberration)

3. Colorization: The pretext task is to color a grayscale input image
4. Generative Modeling: The pretext task is to reconstruct the original input (sometimes with noise or missing piece) while learning meaningful latent representation

![split-brain-autoencoder.png](https://i.loli.net/2021/09/18/NeZDOjASsuY7dgk.png)

## Contrastive Learning
&emsp;&emsp;The goal of contrastive representation learning is to learn such an embedding space in which similar sample pairs stay close to each other while dissimilar ones are far apart. (To some extent similar to metric learning.) Key ingredients are as follows:
* **Heavy Data Augmentation**: It introduces the non-essential variations into examples without modifying semantic meanings.
* **Large Batch Size**: It guarantees that loss function can cover adequate negative samples. (A trick: Memory Bank)
* **Hard Negative Mining**: It's important to find a good way of negative sampling.

### Contrastive Loss (2005)
&emsp;&emsp;Contrastive loss takes a pair of inputs $(x_i,x_j)$ and minimizes the embedding distance when they are from the same class but maximizes the distance otherwise.

$$L(x_i,x_j,\theta)=I_{y_i=y_j}\|f_\theta(x_i)-f_\theta(x_j)\|^2+I_{y_i\not=y_j}\max(0,\varepsilon-\|f_\theta(x_i)-f_\theta(x_j)\|)^2$$

&emsp;&emsp;$\varepsilon$ is a hyperparameter, defining the lower bound distance between samples of different classes.

### Triplet Loss (2015)
&emsp;&emsp;Given one anchor input $x$, we select one positive sample $x^+$ and one negative sample $x^-$. Triplet loss learns to minimize the distance between $x$ and $x^+$ and maximize the distance between $x$ and $x^-$ at the same time.

$$L(x,x^+,x^-)=\sum_{x\in X}\max(0,\|f(x)-f(x^+)\|^2-\|f(x)-f(x^-)\|^2+\varepsilon)$$

&emsp;&emsp;The margin parameter $\varepsilon$ is configured as the minimum offset between distances of similar vs dissimilar pairs.

### Lifted Structured Loss (2015)
&emsp;&emsp;Lifted structured loss utilizes all the pairwise edges within one training batch for better computational efficiency.

![lifted-structured-loss.png](https://i.loli.net/2021/09/18/cahWqFIDjvozxZb.png)

&emsp;&emsp;Let $D_{ij}=\|f(x_i)-f(x_j)\|^2$, then:

$$L=\frac{1}{2\vert P\vert}\sum_{(i,j)\in P}\max(0,L_{ij})^2$$

$$L_{ij}=D_{ij}+\max(\max_{(i,k)\in N}(\varepsilon-D_{ik}),\max_{(j,l)\in N}(\varepsilon-D_{jl}))$$

&emsp;&emsp;$P$ contains the set of positive pairs and $N$ is the set of negative pairs. $L_{ij}$ is used for mining hard negatives.

### N-pair Loss (2016)
&emsp;&emsp;N-pair loss generalizes triplet loss to include comparison with multiple negative samples.

$$\begin{aligned}
    L(x,x^+,\{x_i^-\}_{i=1}^{N-1}) &=\log(1+\sum_{i=1}^{N-1}\exp(f(x)^Tf(x_i^-)-f(x)^Tf(x^+))) \\
    &=-\log\frac{\exp(f(x)^Tf(x^+))}{\exp(f(x)^Tf(x^+))+\sum_{i=1}^{N-1}\exp(f(x)^Tf(x^-_i))}
\end{aligned}$$

&emsp;&emsp;If we only sample one negative sample per class, it is equivalent to the softmax loss for multi-class classification.

### InfoNCE (2018)
&emsp;&emsp;[Representation Learning with Contrastive Predictive Coding](https://plumprc.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2021/08/11/Contrastive-Predictive-Coding/#)

![CPC_detail.png](https://i.loli.net/2021/08/13/msKxnL5Egf1vueb.png)

### Common Setup

TODO: [Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere]()

## Video-Based
A video contains a sequence of semantically related frames.

1. Tracking: tracking moving objects in videos to learn good representation of each frame based on negative sampling

![tracking-videos.png](https://i.loli.net/2021/09/18/f418SctoRhiHlX9.png)

2. Frame Sequence: validate frame order or predicting the arrow of time

![frame-order-validation.png](https://i.loli.net/2021/09/18/nN9DtUOuAr6oFdE.png)

3. Video Colorization: copy colors from a normal reference frame in color to another target frame in grayscale




## Conclusion
* auxiliary task -> prompt