---
title: 机器/深度学习简易入门
date: 2019-08-30 22:08:54
categories:
- ML/DL
tags:
- ML/DL
---

# 前言
&emsp;&emsp;本指导书的目的是帮助从未接触过机器学习的同学在较短的时间内了解相关概念并掌握借助文档实现一些简单模型的能力，笔者尽量以通俗易懂的语言来解释机器学习中的部分概念，不涉及数学推导过程，不会覆盖机器学习的大部分内容。该文建立在笔者三周的项目经验上完成，难免有不足之处，希望有意见的读者给予纠正
* 本文技术栈：简单的分类/回归 ——> 神经网络 ——> 卷积神经网络 ——> 图像识别/分类/分割
* **适用人群**：想在短时间内了解图像分类/分割的同学
* **不适用！**：需要严谨数学推导的读者；希望泛读机器学习各种算法和理论的同学
* [真·机器学习入门](http://www.ai-start.com/)
* REF: [机器学习——周志华](https://www.jianshu.com/p/a50aca402ca6)
# 什么是机器学习？
## 概念
&emsp;&emsp;所谓机器学习，是关于在计算机上从数据中产生**模型**（model）的算法，即**学习算法**（learning algorithm）。有了学习算法，我们就可以把经验数据提供给它，它就能基于这些数据产生模型（i.e.训练）；在面对新的情况时，模型就会给我们提供它基于提供数据总结出来的判断（i.e.验证）。如果说我们人类可以通过发明一套算法（不基于数据）来解决某个问题，那么机器学习就是计算机基于给定的数据通过**学习算法**得到一个**模型**来解决某个问题。<br>
&emsp;&emsp;*笔者注*：一个很明显的区别是，人类发明的算法是显式的，是可以被其他人完美复现的，原理清晰；而计算机学习出来的算法是隐式的，人们并不能完全弄明白其中的机理，并且这种**学习**和数据集有很大的关联。
## 基本术语
&emsp;&emsp;要进行机器学习，首先要有数据。数据的格式一般为（特征，属性值）*e.g. （年龄，15），（身高，180）*，由这些数据组成**数据集**（data set）。从数据中学得模型的过程称为学习或**训练**（training），训练样本组成的集合称为**训练集**（training set）。这个过程通过执行某个学习算法来完成，学得的模型对应了关于数据的某种潜在规律，因此亦称**假设**（hypothesis）*笔者注：相对于真实规律的假设*，机器学习的过程就是根据数据不断优化假设，拟合（逼近）真实规律<br>
&emsp;&emsp;*笔者注*：真实规律即我们希望预测的属性值，比如我们希望预测某个人是小学生还是大学生，我们的数据样例为

| 年龄 | 身高 | 体重 | 类别 |
| :-: | :-: | :-: | :-: |
| 9 | 135 | 40 | 小学生 |
| 19 | 175 | 70 | 大学生 |

> （<年龄，9>, <身高，135>, <体重， 40>， 小学生）
> （<年龄，19>, <身高，175>, <体重， 70>， 大学生）

&emsp;&emsp;这里的前三个键值对即之前提到的（特征，属性值），这里即数据集里的人有三个特征年龄、身高、体重，而小学生/大学生就是我们希望预测的真实规律。在机器学习里，我们就是希望通过这样给定的数据集去预测/拟合/逼近新的真实规律，譬如用我们训练好的模型去预测（<年龄，13>, <身高，165>, <体重， 60>）这样一个人是大学生还是小学生。一般我们称数据集内每个样本的真实规律为标签（label）

## 助记符
* 样本 —— (x, y)
* 特征属性值 —— x
* 真实值 —— y
* 真实映射 —— y(x)
* 预测值 —— h
* 预测映射 —— h(x)<br>

&emsp;&emsp;我们需要通过给定的多个样本找到x与y间的潜在规律 y(x) ，即找到一个假设函数 h(x) 来预测x对应的真实值。而机器学习就是不断优化假设函数 h(x) 去拟合/逼近 真实的y(x)<br>
&emsp;&emsp;*笔者注*：**注意这里的函数不一定是线性映射 ！**

# 分类和回归
## 回归（Regression）
&emsp;&emsp;回归即针对连续值做预测，例如预测明天的平均气温、预测本月消费额、预测房价等，预测函数h(x) 是连续的。最常见的回归是线性回归（linear regression），即预测函数 h(x) 是简单的一次函数
* [线性回归](https://baike.baidu.com/item/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/8190345?fr=aladdin)
* [多项式回归](https://baike.baidu.com/item/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92/21505384?fr=aladdin)<br>

&emsp;&emsp;实际问题里的映射关系往往十分复杂，因此传统的回归往往难以很好的拟合假设函数

## 分类（Classification）
&emsp;&emsp;分类即针对离散值做预测，例如预测图片的种类（多分类），预测是否得糖尿病（二分类）,预测函数 h(x) 依旧是连续函数，但是这里有一个概念，阈值（threshold）。例如在预测是否得糖尿病（二分类）的问题里，我们选择某个特定的分类函数 g(x) ，设定一个阈值（例如0.5），输入数据进行训练，当分类函数作用于假设函数的输出大于0.5则视为得了糖尿病，即：
> 得了糖尿病 —— g(h(x)) > 0.5<br>
> 没得糖尿病 —— g(h(x)) ≤ 0.5

&emsp;&emsp;如上训练即可拟合我们需要的假设函数，在坐标系里拟合出来的 h(x) 往往是非线性的类似于边界一样的曲线，因此在分类问题里假设函数又被称作**决策边界**（decision boundary）<br>
![db](https://raw.githubusercontent.com/plumprc/plumprc.github.io/master/_posts/ML%26DL/material/decision-boundary.png)

&emsp;&emsp;常见的用于分类的函数为logistic函数、tanh(x)双曲正切函数、ReLU线性修正单元等
* [logistic函数的数学推导](https://blog.csdn.net/AriesSurfer/article/details/41310525)

## 模型抽象
&emsp;&emsp;上述两类问题均可抽象为下图所示模型：
![model](https://raw.githubusercontent.com/plumprc/plumprc.github.io/master/_posts/ML%26DL/material/model.png)
&emsp;&emsp;如图，输入数据（+1为偏置单元）训练并得到假设函数，这就是机器学习的一般流程，至于训练的细节则被隐式化了。但要注意，这种简单的拟合方式一般来说无法拟合出较为复杂的映射 h(x) 

# 神经网络
## 模型抽象
![neural-network](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=2689150994,2887220702&fm=26&gp=0.jpg)
&emsp;&emsp;神经网络，顾名思义由多个上面提到的神经单元串联并行组成。如果说简单的往一个单元里输入数据无法拟合较为复杂的映射，那么像这样的复杂的多次拟合从理论上来说可以拟合任何形式的复杂映射。这种多层次的拟合可以参考复合函数<br>
（*笔者注：这样的理解读者在学习BP反向传播算法时会得到更为深刻的理解*）
> x ——> g(x) ——> f(g(x)) ——> h(f(g(x)))

&emsp;&emsp;以上图所示神经网络模型为例，输入数据为x，经过第一层拟合得到了g(x)，再经过后续拟合最终得到了更为复杂的映射函数h(x)。[万能近似定理(Universal approximation theorem)](https://www.sciencedirect.com/science/article/pii/089360809190009T)证明了这样的模型理论上可以以任意精度拟合任意复杂度的连续函数
* [Bonus: 具有一定数学基础的解释](https://www.cnblogs.com/yeluzi/p/7491619.html)

## 另一种解释: 镜头成像
&emsp;&emsp;从结构上来看，多层神经网络和镜头内多个透镜的组成有着相似性，每层网络/镜头在最后的拟合/成像上都起着自己的作用。这里引用了一篇从另一个角度解释神经网络工作机理的文章
* [神经网络与镜头成像](https://www.zhihu.com/question/263672028/answer/430179912)
* [Lessons from Optics, The Other Deep Learning(英文原文)](http://www.argmin.net/2018/01/25/optics/)

# Bonus: ResNet-34
## 论文相关
&emsp;&emsp;

## 模型展示

## 应用示例

# 卷积神经网络

# LeNet-5与手写识别