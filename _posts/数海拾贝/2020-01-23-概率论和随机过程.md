---
title: 概率论和随机过程（更新中）
date: 2021-01-23 23:35:21
categories: 
- 数学
tags:
- 数学
- 概率论
---

## 随机事件及其概率
&emsp;&emsp;[贝特朗投针实验](https://baike.baidu.com/item/%E8%B4%9D%E7%89%B9%E6%9C%97%E6%82%96%E8%AE%BA/9241081)告诉我们，探讨某一事件概率的前提是确定**样本空间**，不同的样本空间所对应的事件概率可能是不同的。

&emsp;&emsp;一般来说，随机试验的所有样本点组成的集合称为样本空间；样本空间的子集为随机事件。

&emsp;&emsp;例：工人生产三个零件，以事件 $A_i(i=1,2,3)$ 表示他生产的第 $i$ 个零件是合格品，那么

|事件|结果表示
|:-:|:-:
|至少有一个合格品|$A_1\cup A_2\cup A_3$
|最多只有两个合格品|$\overline{A_1A_2A_3}$

\* 关于概率的准确理解，请等待版本更新至大数定律后再自行查看

|事件类型|公式
|:-:|:-:
|差事件|$P(A-B)=P(A\overline{B})=P(A)-P(AB)$
|容斥原理|$P(A\cup B)=P(A)+P(B)-P(AB)$
|条件概率|$P(A\vert B)=\displaystyle\frac{P(AB)}{P(B)}$, $P(B)\ne0$
|全概率公式|$P(B)=\sum{P(A_i)P(B\vert A_i)}$
|贝叶斯公式|$P(A_i\vert B)=\displaystyle\frac{P(A_iB)}{P(B)}=\displaystyle\frac{P(A_i)P(B\vert A_i)}{P(B)}$
|事件独立|$P(AB)=P(A)P(B)$
|n 重伯努利试验|$C_n^kp^k(1-p)^{n-k}$, $k=0,1,2...$

* 条件概率相当于更换了事件的样本空间，具体计算中会对样本空间进行缩减。也因此适用于普通概率的一般公式同样适用于条件概率
* 全概率公式脱胎于条件概率，以**两两不相容的完备事件组**对原始事件进行乘积展开，要注意这种展开是**无记忆**的，这也是为什么抓阄原理中概率是均等的
* 贝叶斯定理提出了先验和后验的概念，从时间上割裂了概率，通过先验的不断**迭代**即可得出后验概率
* 独立与互斥没有联系

## 一维随机变量及其分布
* 随机变量：样本空间上的单值实值函数 $X(\omega)$，$\omega$ 为样本点
  * 随机变量实质是样本空间内样本点到实数轴上数的映射形式
* 分布函数：$F(x)=P\{X\leq x\}, x\in(-\infty, \infty)$
  * 分布函数单调不减，且处处右连续
  * 分布函数可看做是概率的势函数
  * $P\{a<X\leq b\}=F(b)-F(a)$，$P\{X=x_0\}=F(x_0)-F(x_0-0)$
* 概率密度：$f(x)$，满足 $F(x)=\displaystyle\int_{-\infty}^xf(t)dt$
  * 连续型随机变量的分布函数必为连续函数
  * $P\{a<X\leq b\}=\displaystyle\int_a^bf(x)dx$

|常见分布|分布形式|概率表达式/密度
|:-:|:-:|:-:
|0-1 分布|$X\sim B(1,p)$|$P\{X=k\}=p^k(1-p)^{1-k},k=0,1$
|二项分布|$X\sim B(n,p)$|$P\{X=k\}=C_n^kp^k(1-p)^{n-k}$
|泊松分布|$X\sim P(\lambda)$|$P\{X=k\}=\displaystyle\frac{\lambda^k}{k!}e^{-\lambda}$
|几何分布||$P\{X=k\}=(1-p)^{k-1}p,k=1,2,\dots$
|均匀分布|$X\sim U(a,b)$|$f(x)=\displaystyle\frac{1}{b-a}\quad a\leq x\leq b$
|指数分布|$X\sim E(\lambda)$|$f(x)=\lambda e^{-\lambda x}\quad x>0$
|正态分布|$X\sim N(\mu,\sigma^2)$|$f(x)=\displaystyle\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$

* 无特殊说明，$k$ 的取值范围均为自然数；概率密度范围外均为 0
* 二项分布刻画的是 n 重伯努利试验的结果
* 泊松分布的分布式脱胎于 $e^x$ 的麦克劳林展开
* 在独立重复试验中，事件 $A$ 首次发生时所进行的实验次数服从几何分布
* 当试验次数足够大时，二项分布的概率结果会趋近泊松分布，满足 $np=\lambda$
* 指数分布具有无记忆性

## 二维随机变量及其分布
* 联合分布函数：$F(x,y)=P\{X\leq x,Y\leq y\}$
  * $F(-\infty,+\infty)=F(-\infty,y)=F(x,-\infty)=0$
  * $F(+\infty,+\infty)=1$
  * 联合分布函数的每个分量单调不减，且处处右连续
* 联合概率分布律：$P\{X=x_i,Y=y_i\}=p_{ij}$
* 边缘分布律：即某分量对另一分量的概率和
* 概率密度：$f(x,y)$，满足 $F(x,y)=\displaystyle\int_{-\infty}^x\int_{-\infty}^yf(u,v)dudv$
  * $P\{(X,Y)\in D\}=\displaystyle\iint_Df(x,y)dxdy$
* 独立性：$F(x,y)=F_X(x)F_Y(y)$

## 数字特征
* 数学期望：


## 大数定律和中心极限定理
在统计活动中，人们发现，在相同条件下大量重复进行一种随机试验时，事件发生的频率值会趋近于某一数值，这个就是最早的大数定律。一般大数定律讨论的是 n 个随机变量平均值的稳定性。

而中心极限定理则是证明了在很一般的条件下，n 个随机变量的和当 n 趋近于正无穷时的极限分布是正态分布

大数定律讲的是样本均值收敛到总体均值

而中心极限定理告诉我们，当样本足够大时，样本均值的分布会慢慢变成正态分布


我们引入示性函数（indicator function）$I_{(A)}$，示性函数只有在事件 A 成立时才返回 1，否则为 0。示性函数满足以下性质：

$$E(I_{(A)})=P(A)\qquad I_{(x\geq a)}\leq\frac{x}{a}$$

![示性函数.jpg](https://i.loli.net/2020/07/28/y9NZJw5SOibd1WT.jpg)

将自变量 $x$ 替换为随机变量 $X$，以上不等式也成立，对两边取均值即可得到 **马尔科夫不等式**。

$$P(X\geq a)\leq\frac{E(X)}{a}$$

对于**切比雪夫不等式**，也可以用类似的示性函数来几何直观证明。对于任意的 $x,a,b$，我们有

$$I_{(|x-a|\geq b)}\leq\frac{(x-a)^2}{b^2}$$

![示性函数2.jpg](https://i.loli.net/2020/07/28/hlpREAjLGck8maX.jpg)

对不等式两边取均值，选取随机变量的均值作为 $a$ ，注意到 $D(X)=E((X-\mu)^2)$，我们有

$$P(|X-\mu|\geq b)\leq\frac{\sigma^2}{b^2}$$
